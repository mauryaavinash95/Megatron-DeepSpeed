# source ~/.bash_profile
# dlconda
cd ~/dl-io/DeepSpeed/
# CMAKE_POSITION_INDEPENDENT_CODE=ON NVCC_PREPEND_FLAGS="--forward-unknown-opts" DS_BUILD_AIO=1 DS_BUILD_CCL_COMM=1 DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_CPU_ADAGRAD=1 DS_BUILD_FUSED_LAMB=1 DS_BUILD_QUANTIZER=1 DS_BUILD_RANDOM_LTD=1 DS_BUILD_TRANSFORMER=1 DS_BUILD_STOCHASTIC_TRANSFORMER=1 DS_BUILD_UTILS=1 DS_BUILD_VELOC_CKPT=1 pip install . --global-option="build_ext" --global-option="-j48" && ds_report
CMAKE_POSITION_INDEPENDENT_CODE=ON NVCC_PREPEND_FLAGS="--forward-unknown-opts" DS_BUILD_AIO=0 DS_BUILD_CCL_COMM=1 DS_BUILD_CPU_ADAM=0 DS_BUILD_FUSED_ADAM=1 DS_BUILD_CPU_ADAGRAD=0 DS_BUILD_FUSED_LAMB=1 DS_BUILD_QUANTIZER=0 DS_BUILD_RANDOM_LTD=1 DS_BUILD_TRANSFORMER=1 DS_BUILD_STOCHASTIC_TRANSFORMER=0 DS_BUILD_UTILS=1 DS_BUILD_VELOC_CKPT=1 pip install . --global-option="build_ext" --global-option="-j48"
cd ~/dl-io/Megatron-DeepSpeed/
# CUDA_VISIBLE_DEVICES=0 deepspeed /home/am6429/dl-io/Megatron-DeepSpeed//pretrain_gpt.py --tensor-model-parallel-size 1 --pipeline-model-parallel-size 1 --num-layers 24 --hidden-size 1024 --num-attention-heads 16 --seq-length 2048 --loss-scale 12 --max-position-embeddings 2048 --micro-batch-size 16 --global-batch-size 16 --train-iters 3 --lr 6.0e-4 --min-lr 6.0e-5 --lr-decay-style cosine --log-interval 1 --eval-iters 3 --eval-interval 3600 --data-path /home/am6429/dl-io/datasets/meg-gpt2_text_document --vocab-file /home/am6429/dl-io/datasets/gpt2-vocab.json --merge-file /home/am6429/dl-io/datasets/gpt2-merges.txt --save-interval 1 --split 98,2,0 --clip-grad 1.0 --weight-decay 0.1 --adam-beta1 0.9 --adam-beta2 0.95 --init-method-std 0.006 --bf16 --checkpoint-activations --exit-interval 10 --save /grand/projects/VeloC/am6429/scratch/gpt2-single/tp1_pp1_dp1 --tensorboard-dir /home/am6429/experiments/results/ckpt_reshape/tensorboard/tp1_pp1_dp1_hd1024_nl24_gbsz16_mbsz16_z1_LR_6.0e-4_6.0e-5_bf16_cont --deepspeed --deepspeed_config=/home/am6429/dl-io/Megatron-DeepSpeed//ds_config.json --zero-stage=1 --deepspeed-activation-checkpointing | tee /home/am6429/dl-io/output/gpt-NN1-OFFLOAD0//log-0.56B-tp1-pp1-dp1-l24-h1024-a16-sl2048-gbs16-mbs-16.log

CUDA_VISIBLE_DEVICES=0 deepspeed /home/am6429/dl-io/Megatron-DeepSpeed//pretrain_gpt.py --tensor-model-parallel-size 1 --pipeline-model-parallel-size 1 --num-layers 24 --hidden-size 1024 --num-attention-heads 16 --seq-length 2048 --loss-scale 12 --max-position-embeddings 2048 --micro-batch-size 16 --global-batch-size 16 --train-iters 3 --lr 6.0e-4 --min-lr 6.0e-5 --lr-decay-style cosine --log-interval 1 --eval-iters 3 --eval-interval 3600 --data-path /home/am6429/dl-io/datasets/meg-gpt2_text_document --vocab-file /home/am6429/dl-io/datasets/gpt2-vocab.json --merge-file /home/am6429/dl-io/datasets/gpt2-merges.txt --save-interval 1 --split 98,2,0 --clip-grad 1.0 --weight-decay 0.1 --adam-beta1 0.9 --adam-beta2 0.95 --init-method-std 0.006 --bf16 --checkpoint-activations --exit-interval 10 --save /grand/projects/VeloC/am6429/scratch/gpt2-single/tp1_pp1_dp1 --tensorboard-dir /home/am6429/experiments/results/ckpt_reshape/tensorboard/tp1_pp1_dp1_hd1024_nl24_gbsz16_mbsz16_z1_LR_6.0e-4_6.0e-5_bf16_cont --deepspeed --deepspeed_config=/home/am6429/dl-io/Megatron-DeepSpeed//ds_config.json --zero-stage=1 | tee /home/am6429/dl-io/output/gpt-NN1-OFFLOAD0//log-0.56B-tp1-pp1-dp1-l24-h1024-a16-sl2048-gbs16-mbs-16.log

